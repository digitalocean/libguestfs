=head1 NAME

virt-v2v - Convert a guest to use KVM

=head1 SYNOPSIS

 virt-v2v -ic vpx://vcenter.example.com/Datacenter/esxi esx_guest

 virt-v2v -ic vpx://vcenter.example.com/Datacenter/esxi esx_guest \
   -o rhev -os rhev.nfs:/export_domain --network rhevm

 virt-v2v -i libvirtxml guest-domain.xml -o local -os /var/tmp

 virt-v2v -i disk disk.img -o local -os /var/tmp

 virt-v2v -i disk disk.img -o glance

=head1 DESCRIPTION

Virt-v2v converts guests from a foreign hypervisor to run on KVM,
managed by libvirt, OpenStack, oVirt, Red Hat Enterprise
Virtualisation (RHEV) or several other targets.  It can currently
convert Red Hat Enterprise Linux and Windows guests running on Xen and
VMware ESX.

There is also a companion front-end called L<virt-p2v(1)> which comes
as an ISO or CD image that can be booted on physical machines.

This manual page documents the rewritten virt-v2v included in
libguestfs E<ge> 1.28.

=head1 INPUT AND OUTPUT MODES

                         ┌────────────┐  ┌─────────▶ -o null
 -i disk ───────────┐    │            │ ─┘┌───────▶ -o local
 -i ova  ─────────┐ └──▶ │ virt-v2v   │ ──┘┌───────▶ -o qemu
                  └────▶ │ conversion │ ───┘┌────────────┐
 ESX ──▶┌────────────┐   │ server     │ ────▶ -o libvirt │─▶ KVM
 Xen ──▶│ -i libvirt ──▶ │            │     │  (default) │
 ... ──▶│  (default) │   │            │ ──┐ └────────────┘
        └────────────┘   │            │ ─┐└──────▶ -o glance
 -i libvirtxml ────────▶ │            │ ┐└─────────▶ -o rhev
                         └────────────┘ └──────────▶ -o vdsm

Virt-v2v has a number of possible input and output modes, selected
using the I<-i> and I<-o> options.  Only one input and output mode can
be selected for each run of virt-v2v.

I<-i libvirt> is used for reading from any libvirt source.  Since
libvirt can connect to many different hypervisors, it is used for
reading guests from VMware ESX, RHEL 5 Xen and more.  The I<-ic>
option selects the precise libvirt source.

I<-i disk> is used for reading from local disk images (mainly for
testing).

I<-i ova> is used for reading from a VMware ova source file.

I<-i libvirtxml> is used to read from libvirt XML files.  This is the
method used by L<virt-p2v(1)> behind the scenes.

I<-o glance> is used for writing to OpenStack Glance.

I<-o libvirt> is used for writing to any libvirt target.  Libvirt can
connect to local or remote KVM hypervisors.  The I<-oc> option selects
the precise libvirt target.

I<-o local> is used to write to a local disk image with a local
libvirt configuration file (mainly for testing).

I<-o qemu> writes to a local disk image with a shell script for
booting the guest directly in qemu (mainly for testing).

I<-o rhev> is used to write to a RHEV-M / oVirt target.  I<-o vdsm>
is only used when virt-v2v runs under VDSM control.

=head1 EXAMPLES

=head2 Convert from VMware vCenter server to local libvirt

You have a VMware vCenter server called C<vcenter.example.com>, a
datacenter called C<Datacenter>, and an ESXi hypervisor called
C<esxi>.  You want to convert a guest called C<esx_guest> to run
locally under libvirt.

 virt-v2v -ic vpx://vcenter.example.com/Datacenter/esxi esx_guest

In this case you will most likely have to run virt-v2v as C<root>,
since it needs to talk to the system libvirt daemon and copy the guest
disks to C</var/lib/libvirt/images>.

For more information see L</INPUT FROM VMWARE VCENTER SERVER> below.

=head2 Convert from ESX to RHEV-M/oVirt

This is the same as the previous example, except you want to send the
guest to a RHEV-M Export Storage Domain which is located remotely
(over NFS) at C<rhev.nfs:/export_domain>.  If you are unclear about
the location of the Export Storage Domain you should check the
settings on your RHEV-M management console.  Guest network
interface(s) are connected to the target network called C<rhevm>.

 virt-v2v -ic vpx://vcenter.example.com/Datacenter/esxi esx_guest \
   -o rhev -os rhev.nfs:/export_domain --network rhevm

In this case the host running virt-v2v acts as a B<conversion server>.

Note that after conversion, the guest will appear in the RHEV-M Export
Storage Domain, from where you will need to import it using the RHEV-M
user interface.  (See L</OUTPUT TO RHEV>).

=head2 Convert disk image to OpenStack glance

Given a disk image from another hypervisor that you want to convert to
run on OpenStack (only KVM-based OpenStack is supported), you can do:

 virt-v2v -i disk disk.img -o glance

To control the name of the image in Glance, use the I<-on> option.

=head2 Convert disk image to disk image

Given a disk image from another hypervisor that you want to convert to
run on KVM, you have two options.  The simplest way is to try:

 virt-v2v -i disk disk.img -o local -os /var/tmp

where virt-v2v guesses everything about the input C<disk.img> and (in
this case) writes the converted result to C</var/tmp>.

A more complex method is to write some
L<libvirt XML|http://libvirt.org/formatdomain.html> describing the
input guest (if you can get the source hypervisor to provide you with
libvirt XML, then so much the better).  You can then do:

 virt-v2v -i libvirtxml guest-domain.xml -o local -os /var/tmp

Since C<guest-domain.xml> contains the path(s) to the guest disk
image(s) you do not need to specify the name of the disk image on the
command line.

To convert a local disk image and immediately boot it in local
qemu, do:

 virt-v2v -i disk disk.img -o qemu -os /var/tmp --qemu-boot

=head1 OPTIONS

=over 4

=item B<--help>

Display help.

=item B<-b> ...

=item B<--bridge> ...

See I<--network> below.

=item B<--debug-gc>

Debug garbage collection and memory allocation.  This is only useful
when debugging memory problems in virt-v2v or the OCaml libguestfs
bindings.

=item B<--debug-overlays>

Save the overlay file(s) created during conversion.  This option is
only used for debugging virt-v2v and may be removed in a future
version.

=item B<-i disk>

Set the input method to I<disk>.

In this mode you can read a virtual machine disk image with no
metadata.  virt-v2v tries to guess the best default metadata.  This is
usually adequate but you can get finer control (eg. of memory and
vCPUs) by using I<-i libvirtxml> instead.  Only guests that use a single
disk can be imported this way.

=item B<-i libvirt>

Set the input method to I<libvirt>.  This is the default.

In this mode you have to specify a libvirt guest name or UUID on the
command line.  You may also specify a libvirt connection URI (see
I<-ic>).

=item B<-i libvirtxml>

Set the input method to I<libvirtxml>.

In this mode you have to pass a libvirt XML file on the command line.
This file is read in order to get metadata about the source guest
(such as its name, amount of memory), and also to locate the input
disks.  See L</MINIMAL XML FOR -i libvirtxml OPTION> below.

=item B<-i local>

This is the same as I<-i disk>.

=item B<-i ova>

Set the input method to I<ova>.

In this mode you can read a VMware ova file.  Virt-v2v will read the
ova manifest file and check the vmdk volumes for validity (checksums)
as well as analyzing the ovf file, and then convert the guest.

=item B<-ic> libvirtURI

Specify a libvirt connection URI to use when reading the guest.  This
is only used when S<I<-i libvirt>>.

Only local libvirt connections, ESX connections, or RHEL 5 Xen remote
connections can be used.  Other remote libvirt connections will not
work in general.

See also L</INPUT FROM VMWARE VCENTER SERVER>,
L</INPUT FROM RHEL 5 XEN> below.

=item B<-if> format

For I<-i disk> only, this specifies the format of the input disk
image.  For other input methods you should specify the input
format in the metadata.

=item B<--machine-readable>

This option is used to make the output more machine friendly
when being parsed by other programs.  See
L</MACHINE READABLE OUTPUT> below.

=item B<-n> in:out

=item B<-n> out

=item B<--network> in:out

=item B<--network> out

=item B<-b> in:out

=item B<-b> out

=item B<--bridge> in:out

=item B<--bridge> out

Map network (or bridge) called C<in> to network (or bridge) called
C<out>.  If no C<in:> prefix is given, all other networks (or bridges)
are mapped to C<out>.

See L</NETWORKS AND BRIDGES> below.

=item B<--no-copy>

Don't copy the disks.  Instead, conversion is performed (and thrown
away), and metadata is written, but no disks are created.  See
also discussion of S<I<-o null>> below.

This is useful in two cases: Either you want to test if conversion is
likely to succeed, without the long copying process.  Or you are only
interested in looking at the metadata.

This option is not compatible with I<-o libvirt> since it would create
a faulty guest (one with no disks).

This option is not compatible with I<-o glance> for technical reasons.

=item B<--no-trim all>

=item B<--no-trim> mp[,mp...]

By default virt-v2v runs L<fstrim(8)> to reduce the amount of data
that needs to be copied.  This is known to break some buggy
bootloaders causing boot failures after conversion (see for example
L<https://bugzilla.redhat.com/show_bug.cgi?id=1141145#c27>).

You can use I<--no-trim all> to disable all trimming.  Note this will
greatly increase the amount of data that has to be copied and can make
virt-v2v run much more slowly.

You can also disable trimming on selected filesystems only (specified
by a comma-separated list of their mount point(s) in the guest).
Typically you would use I<--no-trim /boot> to work around the grub bug
mentioned above.

You can also disable trimming on partitions using the libguestfs
naming scheme for devices, eg: I<--no-trim /dev/sdb2> means do not
trim the second partition on the second block device.  Use
L<virt-filesystems(1)> to list filesystem names in a guest.

=item B<-o disk>

This is the same as I<-o local>.

=item B<-o glance>

Set the output method to OpenStack Glance.  In this mode the converted
guest is uploaded to Glance.  You can control the image name by setting
the I<-on> option.

=item B<-o libvirt>

Set the output method to I<libvirt>.  This is the default.

In this mode, the converted guest is created as a libvirt guest.  You
may also specify a libvirt connection URI (see I<-oc>).

See L</OUTPUT TO LIBVIRT> below.

=item B<-o local>

Set the output method to I<local>.

In this mode, the converted guest is written to a local directory
specified by I<-os /dir> (the directory must exist).  The converted
guest's disks are written as:

 /dir/name-sda
 /dir/name-sdb
 [etc]

and a libvirt XML file is created containing guest metadata:

 /dir/name.xml

where C<name> is the guest name.

=item B<-o null>

Set the output method to I<null>.

The guest is converted and copied (unless you also specify
I<--no-copy>), but the results are thrown away and no metadata is
written.

=item B<-o ovirt>

This is the same as I<-o rhev>.

=item B<-o qemu>

Set the output method to I<qemu>.

This is similar to I<-o local>, except that a shell script is written
which you can use to boot the guest in qemu.  The converted disks and
shell script are written to the directory specified by I<-os>.

When using this output mode, you can also specify the I<--qemu-boot>
option which boots the guest under qemu immediately.

=item B<-o rhev>

Set the output method to I<rhev>.

The converted guest is written to a RHEV Export Storage Domain.  The
I<-os> parameter must also be used to specify the location of the
Export Storage Domain.  Note this does not actually import the guest
into RHEV.  You have to do that manually later using the UI.

See L</OUTPUT TO RHEV> below.

=item B<-o vdsm>

Set the output method to I<vdsm>.

This mode is similar to I<-o rhev> but is only used by RHEV VDSM
when it runs virt-v2v under VDSM control.

=item B<-oa sparse>

=item B<-oa preallocated>

Set the output file allocation mode.  The default is C<sparse>.

=item B<-oc> libvirtURI

Specify a libvirt connection to use when writing the converted guest.
This is only used when S<I<-o libvirt>>.  See L</OUTPUT TO LIBVIRT> below.

Only local libvirt connections can be used.  Remote libvirt
connections will not work.

=item B<-of> format

When converting the guest, convert the disks to the given format.

If not specified, then the input format is used.

=item B<-on> name

Rename the guest when converting it.  If this option is not used then
the output name is the same as the input name.

=item B<-os> storage

The location of the storage for the converted guest.

For I<-o libvirt>, this is a libvirt directory pool
(see S<C<virsh pool-list>>) or pool UUID.

For I<-o local> and I<-o qemu>, this is a directory name.  The
directory must exist.

For I<-o rhev>, this can be an NFS path of the Export Storage Domain
of the form C<E<lt>hostE<gt>:E<lt>pathE<gt>>, eg:

 rhev-storage.example.com:/rhev/export

The NFS export must be mountable and writable by the user and host
running virt-v2v, since the virt-v2v program has to actually mount it
when it runs.  So you probably have to run virt-v2v as C<root>.

B<Or:> You can mount the Export Storage Domain yourself, and point
I<-os> to the mountpoint.  Note that virt-v2v will still need to write
to this remote directory, so virt-v2v will still need to run as
C<root>.

You will get an error if virt-v2v is unable to mount/write to the
Export Storage Domain.

=item B<--print-source>

Print information about the source guest and stop.  This option is
useful when you are setting up network and bridge maps.
See L</NETWORKS AND BRIDGES>.

=item B<--qemu-boot>

When using I<-o qemu> only, this boots the guest immediately after
virt-v2v finishes.

=item B<-q>

=item B<--quiet>

This disables progress bars and other unnecessary output.

=item B<--root ask>

=item B<--root single>

=item B<--root first>

=item B<--root> /dev/sdX

=item B<--root> /dev/VG/LV

Choose the root filesystem to be converted.

In the case where the virtual machine is dual-boot or multi-boot, or
where the VM has other filesystems that look like operating systems,
this option can be used to select the root filesystem (a.k.a. C<C:>
drive or C</>) of the operating system that is to be converted.  The
Windows Recovery Console, certain attached DVD drives, and bugs in
libguestfs inspection heuristics, can make a guest look like a
multi-boot operating system.

The default in virt-v2v E<le> 0.7.1 was S<I<--root single>>, which
causes virt-v2v to die if a multi-boot operating system is found.

Since virt-v2v E<ge> 0.7.2 the default is now S<I<--root ask>>: If the
VM is found to be multi-boot, then virt-v2v will stop and list the
possible root filesystems and ask the user which to use.  This
requires that virt-v2v is run interactively.

S<I<--root first>> means to choose the first root device in the case
of a multi-boot operating system.  Since this is a heuristic, it may
sometimes choose the wrong one.

You can also name a specific root device, eg. S<I<--root /dev/sda2>>
would mean to use the second partition on the first hard drive.  If
the named root device does not exist or was not detected as a root
device, then virt-v2v will fail.

Note that there is a bug in grub which prevents it from successfully
booting a multiboot system if VirtIO is enabled.  Grub is only able to
boot an operating system from the first VirtIO disk.  Specifically,
C</boot> must be on the first VirtIO disk, and it cannot chainload an
OS which is not in the first VirtIO disk.

=item B<--vdsm-image-uuid> UUID

=item B<--vdsm-vol-uuid> UUID

=item B<--vdsm-vm-uuid> UUID

Normally the RHEV output mode chooses random UUIDs for the target
guest.  However VDSM needs to control the UUIDs and passes these
parameters when virt-v2v runs under VDSM control.  The parameters
control:

=over 4

=item *

the image directory of each guest disk (I<--vdsm-image-uuid>) (this
option is passed once for each guest disk)

=item *

UUIDs for each guest disk (I<--vdsm-vol-uuid>) (this option
is passed once for each guest disk)

=item *

the VM and OVF file (I<--vdsm-vm-uuid>).

=back

The format of UUIDs is: C<12345678-1234-1234-1234-123456789abc> (each
hex digit can be C<0-9> or C<a-f>), conforming to S<OSF DCE 1.1>.

These options can only be used with I<-o vdsm>.

=item B<-v>

=item B<--verbose>

Enable verbose messages for debugging.

=item B<-V>

=item B<--version>

Display version number and exit.

=item B<--vmtype desktop>

=item B<--vmtype server>

For the I<-o rhev> or I<-o vdsm> targets only, specify the type of
guest.  You can set this to C<desktop> or C<server>.  If the option is
not given, then a suitable default is chosen based on the detected
guest operating system.

=item B<-x>

Enable tracing of libguestfs API calls.

=back

=head1 XEN PARAVIRTUALIZED GUESTS

Older versions of virt-v2v could turn a Xen paravirtualized (PV) guest
into a KVM guest by installing a new kernel.  This version of virt-v2v
does I<not> attempt to install any new kernels.  Instead it will give
you an error if there are I<only> Xen PV kernels available.

Therefore before conversion you should check that a regular kernel is
installed.  For some older Linux distributions, this means installing
a kernel from the table below:

 RHEL 3         (Does not apply, as there was no Xen PV kernel)
 
 RHEL 4         i686 with > 10GB of RAM: install 'kernel-hugemem'
                i686 SMP: install 'kernel-smp'
                other i686: install 'kernel'
                x86-64 SMP with > 8 CPUs: install 'kernel-largesmp'
                x86-64 SMP: install 'kernel-smp'
                other x86-64: install 'kernel'
 
 RHEL 5         i686: install 'kernel-PAE'
                x86-64: install 'kernel'
 
 SLES 10        i586 with > 10GB of RAM: install 'kernel-bigsmp'
                i586 SMP: install 'kernel-smp'
                other i586: install 'kernel-default'
                x86-64 SMP: install 'kernel-smp'
                other x86-64: install 'kernel-default'
 
 SLES 11+       i586: install 'kernel-pae'
                x86-64: install 'kernel-default'

 Windows        (Does not apply, as there is no Xen PV Windows kernel)

=head1 ENABLING VIRTIO

"Virtio" is the name for a set of drivers which make disk (block
device), network and other guest operations work much faster on KVM.

Older versions of virt-v2v could install these drivers for certain
Linux guests.  This version of virt-v2v does I<not> attempt to install
new Linux kernels or drivers, but will warn you if they are not
installed already.

In order to enable virtio, and hence improve performance of the guest
after conversion, you should ensure that the B<minimum> versions of
packages are installed I<before> conversion, by consulting the table
below.

 RHEL 3         No virtio drivers are available
 
 RHEL 4         kernel >= 2.5.9-89.EL
 
 RHEL 5         kernel >= 2.6.18-128.el5
                lvm2 >= 2.02.40-6.el5
                selinux-policy-targeted >= 2.4.6-203.el5
 
 RHEL 6+        All versions support virtio
 
 Fedora         All versions support virtio
 
 SLES 11+       All versions support virtio
 
 SLES 10        kernel >= 2.6.16.60-0.85.1
 
 OpenSUSE 11+   All versions support virtio
 
 OpenSUSE 10    kernel >= 2.6.25.5-1.1

 Windows        Drivers are installed from /usr/share/virtio-win
                if present

=head1 NETWORKS AND BRIDGES

Guests are usually connected to one or more networks, and when
converted to the target hypervisor you usually want to reconnect those
networks at the destination.  The options I<--network> and I<--bridge>
allow you to do that.

If you are unsure of what networks and bridges are in use on the
source hypervisor, then you can examine the source metadata (libvirt
XML, vCenter information, etc.).  Or you can run virt-v2v with the
I<--print-source> option which causes virt-v2v to print out the
information it has about the guest on the source and then exit.

In the I<--print-source> output you will see a section showing the
guest's Network Interface Cards (NICs):

 $ virt-v2v [-i ...] --print-source name
 [...]
 NICs:
     Network "default" mac: 52:54:00:d0:cf:0e

This is typical of a libvirt guest: It has a single network interface
connected to a network called C<default>.

To map a specific network to a target network, for example C<default>
on the source to C<rhevm> on the target, use:

 virt-v2v [...] --network default:rhevm

To map every network to a target network, use:

 virt-v2v [...] --network rhevm

Bridges are handled in the same way, but you have to use the
I<--bridge> option instead.  For example:

 $ virt-v2v [-i ...] --print-source name
 [...]
 NICs:
     Bridge "br0"
 
 $ virt-v2v [...] --bridge br0:targetbr

=head1 INPUT FROM VMWARE VCENTER SERVER

Virt-v2v is able to import guests from VMware vCenter Server.

Note that virt-v2v B<cannot> import guests directly from an ESXi
hypervisor.

Virt-v2v uses libvirt for access to vCenter, and therefore the input
mode should be I<-i libvirt>.  As this is the default, you don't need
to specify it on the command line.

=head2 ESX: REMOVE VMWARE TOOLS FROM WINDOWS GUESTS

For Windows guests, you should remove VMware tools before conversion.
Although this is not strictly necessary, and the guest will still be
able to run, if you don't do this then the converted guest will
complain on every boot.  The tools cannot be removed after conversion
because the uninstaller checks if it is running on VMware and refuses
to start (which is also the reason that virt-v2v cannot remove them).

This is not necessary for Linux guests, as virt-v2v is able to remove
VMware tools.

=head2 ESX: VCENTER URI

The libvirt URI of a vCenter server looks something like this:

 vpx://user@server/Datacenter/esxi

where:

=over 4

=item C<user@>

is the (optional, but recommended) user to connect as

=item C<server>

is the vCenter Server (I<not> hypervisor)

=item C<Datacenter>

is the name of the datacenter

=item C<esxi>

is the name of the ESXi hypervisor running the guest.

=back

If the VMware deployment is using clusters and/or folders, then these
may need to be added to the URI, eg:

 vpx://user@server/Datacenter/cluster1/esxi

For full details of libvirt URIs, see: L<http://libvirt.org/drvesx.html>

Typical errors from libvirt / virsh when the URI is wrong include:

=over 4

=item *

Could not find datacenter specified in [...]

=item *

Could not find compute resource specified in [...]

=item *

Path [...] does not specify a compute resource

=item *

Path [...] does not specify a host system

=item *

Could not find host system specified in [...]

=back

=head2 ESX: TEST LIBVIRT CONNECTION TO VCENTER

Use the L<virsh(1)> command to list the guests on the vCenter Server
like this:

 $ virsh -c 'vpx://root@vcenter.example.com/Datacenter/esxi' list --all
 Enter root's password for vcenter.example.com: ***
 
  Id    Name                           State
 ----------------------------------------------------
  -     Fedora 20                      shut off
  -     Windows 2003                   shut off

If you get an error "Peer certificate cannot be authenticated with
given CA certificates" or similar, then you can either import the ESX
host's certificate, or bypass signature verification by adding the
C<?no_verify=1> flag:

 $ virsh -c 'vpx://root@vcenter.example.com/Datacenter/esxi?no_verify=1' list --all

You should also try dumping the metadata from any guest on your
server, like this:

 $ virsh -c 'vpx://root@vcenter.example.com/Datacenter/esxi' dumpxml "Windows 2003"
 <domain type='vmware'>
   <name>Windows 2003</name>
   [...]
 </domain>

B<If the above commands do not work, then virt-v2v is not going to
work either>.  Fix your libvirt configuration and/or your VMware
vCenter Server before continuing.

=head2 ESX: IMPORTING A GUEST

To import a particular guest from vCenter Server, do:

 $ virt-v2v -ic 'vpx://root@vcenter.example.com/Datacenter/esxi?no_verify=1' \
   "Windows 2003" \
   -o local -os /var/tmp

where C<Windows 2003> is the name of the guest (which must be shut
down).

Note that you may be asked for the vCenter password I<twice>.  This
happens once because libvirt needs it, and a second time because
virt-v2v itself connects directly to the server.

In this case the output flags are set to write the converted guest to
a temporary directory as this is just an example, but you can also
write to libvirt or any other supported target.

=head1 INPUT FROM RHEL 5 XEN

Virt-v2v is able to import Xen guests from RHEL 5 Xen hosts.

Virt-v2v uses libvirt for access to the remote Xen host, and therefore
the input mode should be I<-i libvirt>.  As this is the default, you
don't need to specify it on the command line.

=head2 XEN: SET UP SSH-AGENT ACCESS TO XEN HOST

Currently you must enable passwordless SSH access to the remote Xen host
from the virt-v2v conversion server.

You must also use ssh-agent, and add your ssh public key to
C</root/.ssh/authorized_keys> (on the Xen host).

After doing this, you should check that passwordless access works
from the virt-v2v server to the Xen host.  For example:

 $ ssh root@xen.example.com
 [ logs straight into the shell, no password is requested ]

Note that password-interactive and Kerberos access are B<not>
supported.  You B<have> to set up ssh access using ssh-agent and
authorized_keys.

=head2 XEN: TEST LIBVIRT CONNECTION TO REMOTE XEN HOST

Use the L<virsh(1)> command to list the guests on the remote Xen host:

 $ virsh -c xen+ssh://root@xen.example.com list --all
  Id    Name                           State
 ----------------------------------------------------
  0     Domain-0                       running
  -     rhel49-x86_64-pv               shut off

You should also try dumping the metadata from any guest on your
server, like this:

 $ virsh -c xen+ssh://root@xen.example.com dumpxml rhel49-x86_64-pv
 <domain type='xen'>
   <name>rhel49-x86_64-pv</name>
   [...]
 </domain>

B<If the above commands do not work, then virt-v2v is not going to
work either>.  Fix your libvirt configuration or the remote server
before continuing.

=head2 XEN: IMPORTING A GUEST

To import a particular guest from a Xen server, do:

 $ virt-v2v -ic 'xen+ssh://root@xen.example.com' \
   rhel49-x86_64-pv \
   -o local -os /var/tmp

where C<rhel49-x86_64-pv> is the name of the guest (which must be shut
down).

In this case the output flags are set to write the converted guest to
a temporary directory as this is just an example, but you can also
write to libvirt or any other supported target.

=head1 OUTPUT TO LIBVIRT

The I<-o libvirt> option lets you upload the converted guest to
a libvirt-managed host.  There are several limitations:

=over 4

=item *

You can only use a local libvirt connection [see below for how to
workaround this].

=item *

The I<-os pool> option must specify a directory pool, not anything
more exotic such as iSCSI [but see below].

=item *

You can only upload to a KVM hypervisor.

=back

B<To output to a remote libvirt instance and/or a non-directory storage pool>
you have to use the following workaround:

=over 4

=item 1.

Use virt-v2v in I<-o local> mode to convert the guest disks and
metadata into a local temporary directory:

 virt-v2v [...] -o local -os /var/tmp

This creates two (or more) files in C</var/tmp> called:

 /var/tmp/NAME.xml     # the libvirt XML (metadata)
 /var/tmp/NAME-sda     # the guest's first disk

(for C<NAME> substitute the guest's name).

=item 2.

Upload the converted disk(s) into the storage pool called C<POOL>:

 size=$(stat -c%s /var/tmp/NAME-sda)
 virsh vol-create-as POOL NAME-sda $size --format raw
 virsh vol-upload --pool POOL NAME-sda /var/tmp/NAME-sda

=item 3.

Edit C</var/tmp/NAME.xml> to change C</var/tmp/NAME-sda> to the pool
name.  In other words, locate the following bit of XML:

 <disk type='file' device='disk'>
   <driver name='qemu' type='raw' cache='none' />
   <source file='/var/tmp/NAME-sda' />
   <target dev='hda' bus='ide' />
 </disk>

and change two things: The C<type='file'> attribute must be changed to
C<type='volume'>, and the C<E<lt>sourceE<gt>> element must be changed
to include C<pool> and C<volume> attributes:

 <disk type='volume' device='disk'>
   ...
   <source pool='POOL' volume='NAME-sda' />
   ...
 </disk>

=item 4.

Define the final guest in libvirt:

 virsh define /var/tmp/NAME.xml

=back

=head1 OUTPUT TO RHEV

This section only applies to the I<-o rhev> output mode.  If you use
virt-v2v from the RHEV-M user interface, then behind the scenes the
import is managed by VDSM using the I<-o vdsm> output mode (which end
users should not try to use directly).

You have to specify I<-o rhev> and an I<-os> option that points to the
RHEV-M Export Storage Domain.  You can either specify the NFS server
and mountpoint, eg. S<C<-os rhev-storage:/rhev/export>>, or you can
mount that first and point to the directory where it is mounted,
eg. S<C<-os /tmp/mnt>>.  Be careful not to point to the Data Storage
Domain by accident as that will not work.

On successful completion virt-v2v will have written the new guest to
the Export Storage Domain, but it will not yet be ready to run.  It
must be imported into RHEV using the UI before it can be used.

In RHEV E<ge> 2.2 this is done from the Storage tab.  Select the
export domain the guest was written to.  A pane will appear underneath
the storage domain list displaying several tabs, one of which is "VM
Import".  The converted guest will be listed here.  Select the
appropriate guest an click "Import".  See the RHEV documentation for
additional details.

If you export several guests, then you can import them all at the same
time through the UI.

=head1 RESOURCE REQUIREMENTS

=head2 Network

The most important resource for virt-v2v appears to be network
bandwidth.  Virt-v2v should be able to copy guest data at gigabit
ethernet speeds or greater.

Ensure that the network connections between servers (conversion
server, NFS server, vCenter, Xen) are as fast and as low latency as
possible.

=head2 Disk space

Virt-v2v places potentially large temporary files in C<$TMPDIR> (which
is C</var/tmp> if you don't set it).  Using tmpfs is a bad idea.

For each guest disk, an overlay is stored temporarily.  This stores
the changes made during conversion, and is used as a cache.  The
overlays are not particularly large - tens or low hundreds of
megabytes per disk is typical.  In addition to the overlay(s), input
and output methods may use disk space, as outlined in the table below.

=over 4

=item I<-i ova>

This temporarily places a full copy of the uncompressed source disks
in C<$TMPDIR>.

=item I<-o glance>

This temporarily places a full copy of the output disks in C<$TMPDIR>.

=item I<-o local>

=item I<-o qemu>

You must ensure there is sufficient space in the output directory for
the converted guest.

=item I<-o null>

This temporarily places a full copy of the output disks in C<$TMPDIR>.

=back

=head2 VMware vCenter resources

Copying from VMware vCenter is currently quite slow, but we believe
this to be an issue with VMware.  Ensuring the VMware ESXi hypervisor
and vCenter guest are running on fast hardware with plenty of memory
should alleviate this.

=head2 Compute power and RAM

Virt-v2v is not especially compute or RAM intensive.  If you are
running many parallel conversions, then you may consider allocating
one CPU core and 512 MB - 1 GB of RAM per running instance.

Virt-v2v can be run in a virtual machine.

=head1 POST-CONVERSION TASKS

=head2 Guest network configuration

Virt-v2v cannot currently reconfigure a guest's network configuration.
If the converted guest is not connected to the same subnet as the
source, its network configuration may have to be updated.  See also
L<virt-customize(1)>.

=head2 Converting a Windows guest

When converting a Windows guests, the conversion process is split into
two stages:

=over

=item 1

Offline conversion.

=item 2

First boot.

=back

The guest will be bootable after the offline conversion stage, but
will not yet have all necessary drivers installed to work correctly.
These will be installed automatically the first time the guest boots.

B<N.B.> Take care not to interrupt the automatic driver installation
process when logging in to the guest for the first time, as this may
prevent the guest from subsequently booting correctly.

=head2 Windows Recovery Console

Virt-v2v does not support conversion of the Windows Recovery Console.
If a guest has a recovery console installed and VirtIO was enabled
during conversion, attempting to boot the recovery console will result
in a BSOD.

Windows XP x86 does not support the Windows Recovery Console on VirtIO
systems, so there is no resolution to this.  However, on Windows XP
AMD64 and Windows 2003 (x86 and AMD64), the recovery console can be
re-installed after conversion.  The re-installation procedure is the
same as the initial installation procedure.  It is not necessary to
remove the recovery console first.  Following re-installation, the
recovery console will work as intended.

=head1 RUNNING VIRT-V2V AS ROOT OR NON-ROOT

Nothing in virt-v2v inherently needs root access, and it will run just
fine as a non-root user.  However, certain external features may
require either root or a special user:

=over 4

=item Mounting the Export Storage Domain

When using I<-o rhev -os server:/esd> virt-v2v has to have sufficient
privileges to NFS mount the Export Storage Domain from C<server>.

You can avoid needing root here by mounting it yourself before running
virt-v2v, and passing I<-os /mountpoint> instead, but first of all
read the next S<section ...>

=item Writing to the Export Storage Domain as 36:36

RHEV-M cannot read files and directories from the Export Storage
Domain unless they have UID:GID 36:36.  You will see VM import
problems if the UID:GID is not correct.

When you run virt-v2v I<-o rhev> as root, virt-v2v attempts to create
files and directories with the correct ownership.  If you run virt-v2v
as non-root, it will probably still work, but you will need to
manually change ownership after virt-v2v has finished.

=item Writing to libvirt

When using I<-o libvirt>, you may need to run virt-v2v as root so that
it can write to the libvirt system instance (ie. C<qemu:///system>)
and to the default location for disk images (usually
C</var/lib/libvirt/images>).

You can avoid this by setting up libvirt connection authentication,
see L<http://libvirt.org/auth.html>.  Alternatively, use
I<-oc qemu:///session>, which will write to your per-user libvirt
instance.

=item Writing to Glance

This does I<not> need root (in fact it probably won't work), but may
require either a special user and/or for you to source a script that
sets authentication environment variables.  Consult the Glance
documentation.

=back

=head1 DEBUGGING RHEV-M IMPORT FAILURES

When you export to the RHEV-M Export Storage Domain, and then import
that guest through the RHEV-M UI, you may encounter an import failure.
Diagnosing these failures is infuriatingly difficult as the UI
generally hides the true reason for the failure.

There are two log files of interest.  The first is stored on the
RHEV-M server itself, and is called
C</var/log/ovirt-engine/engine.log>

The second file, which is the most useful, is found on the SPM host
(SPM stands for "Storage Pool Manager").  This is a RHEV node that is
elected to do all metadata modifications in the data center, such as
image or snapshot creation.  You can find out which host is the
current SPM from the "Hosts" tab "Spm Status" column.  Once you have
located the SPM, log into it and grab the file
C</var/log/vdsm/vdsm.log> which will contain detailed error messages
from low-level commands.

=head1 MINIMAL XML FOR -i libvirtxml OPTION

When using the I<-i libvirtxml> option, you have to supply some
libvirt XML.  Writing this from scratch is hard, so the template below
is helpful.

B<Note this should only be used for testing and/or where you know what
you're doing!>  If you have libvirt metadata for the guest, always use
that instead.

 <domain type='kvm'>
   <name>NAME</name>
   <memory>1048576</memory>
   <vcpu>2</vcpu>
   <os>
     <type>hvm</type>
     <boot dev='hd'/>
   </os>
   <features>
     <acpi/>
     <apic/>
     <pae/>
   </features>
   <devices>
     <disk type='file' device='disk'>
       <driver name='qemu' type='raw'/>
       <source file='/path/to/disk/image'/>
       <target dev='hda' bus='ide'/>
     </disk>
     <interface type='network'>
       <mac address='52:54:00:01:02:03'/>
       <source network='default'/>
       <model type='rtl8139'/>
     </interface>
   </devices>
 </domain>

=head1 MACHINE READABLE OUTPUT

The I<--machine-readable> option can be used to make the output more
machine friendly, which is useful when calling virt-v2v from
other programs, GUIs etc.

There are two ways to use this option.

Firstly use the option on its own to query the capabilities of the
virt-v2v binary.  Typical output looks like this:

 $ virt-v2v --machine-readable
 virt-v2v
 libguestfs-rewrite
 input:disk
 [...]
 output:local
 [...]
 convert:enterprise-linux
 convert:windows

A list of features is printed, one per line, and the program exits
with status 0.

The C<input:> and C<output:> features refer to I<-i> and I<-o> (input
and output mode) options supported by this binary.  The C<convert:>
features refer to guest types that this binary knows how to convert.

Secondly use the option in conjunction with other options to make the
regular program output more machine friendly.

At the moment this means:

=over 4

=item 1.

Progress bar messages can be parsed from stdout by looking for this
regular expression:

 ^[0-9]+/[0-9]+$

=item 2.

The calling program should treat messages sent to stdout (except for
progress bar messages) as status messages.  They can be logged and/or
displayed to the user.

=item 3.

The calling program should treat messages sent to stderr as error
messages.  In addition, virt-v2v exits with a non-zero status
code if there was a fatal error.

=back

Virt-v2v E<le> 0.9.1 did not support the I<--machine-readable>
option at all.  The option was added when virt-v2v was rewritten in 2014.

=head1 FILES

=over 4

=item C</usr/share/virtio-win>

(Optional)

If this directory is present, then virtio drivers for Windows guests
will be found from this directory and installed in the guest during
conversion.

=back

=head1 ENVIRONMENT VARIABLES

=over 4

=item C<TMPDIR>

Location of the temporary directory used for the potentially large
temporary overlay file.

See the L</Disk space> section above.

=item C<VIRT_TOOLS_DATA_DIR>

This can point to the directory containing data files used for Windows
conversion.

Normally you do not need to set this.  If not set, a compiled-in
default will be used (something like C</usr/share/virt-tools>).

This directory may contain the following files:

=over 4

=item C<rhsrvany.exe>

(Required when doing conversions of Windows guests)

This is the RHSrvAny Windows binary, used to install a "firstboot"
script in the guest during conversion of Windows guests.

See also: C<https://github.com/rwmjones/rhsrvany>

=item C<rhev-apt.exe>

(Optional)

The RHEV Application Provisioning Tool (RHEV APT).  If this file is
present, then RHEV APT will be installed in the Windows guest during
conversion.  This tool is a guest agent which ensures that the virtio
drivers remain up to date when the guest is running on Red Hat
Enterprise Virtualization (RHEV).

This file comes from Red Hat Enterprise Virtualization (RHEV), and is
not distributed with virt-v2v.

=back

=back

For other environment variables, see L<guestfs(3)/ENVIRONMENT VARIABLES>.

=head1 SEE ALSO

L<virt-p2v(1)>,
L<virt-customize(1)>,
L<virt-df(1)>,
L<virt-filesystems(1)>,
L<virt-sparsify(1)>,
L<virt-sysprep(1)>,
L<guestfs(3)>,
L<guestfish(1)>,
L<qemu-img(1)>,
L<fstrim(8)>,
L<http://libguestfs.org/>.

=head1 AUTHORS

Richard W.M. Jones L<http://people.redhat.com/~rjones/>

Matthew Booth

Mike Latimer

Shahar Havivi

Tingting Zheng

=head1 COPYRIGHT

Copyright (C) 2009-2014 Red Hat Inc.
